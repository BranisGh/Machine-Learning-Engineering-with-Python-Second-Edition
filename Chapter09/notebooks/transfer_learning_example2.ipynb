{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f09be31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #https://huggingface.co/docs/transformers/v4.29.1/en/model_doc/bert#transformers.BertForSequenceClassification\n",
    "# import torch\n",
    "# from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\")\n",
    "# model = BertForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\", problem_type=\"multi_label_classification\")\n",
    "\n",
    "# inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     logits = model(**inputs).logits\n",
    "\n",
    "# predicted_class_ids = torch.arange(0, logits.shape[-1])[torch.sigmoid(logits).squeeze(dim=0) > 0.5]\n",
    "\n",
    "# # To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`\n",
    "# num_labels = len(model.config.id2label)\n",
    "# model = BertForSequenceClassification.from_pretrained(\n",
    "#     \"textattack/bert-base-uncased-yelp-polarity\", num_labels=num_labels, problem_type=\"multi_label_classification\"\n",
    "# )\n",
    "\n",
    "# labels = torch.sum(\n",
    "#     torch.nn.functional.one_hot(predicted_class_ids[None, :].clone(), num_classes=num_labels), dim=1\n",
    "# ).to(torch.float)\n",
    "# loss = model(**inputs, labels=labels).loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f598a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# #dataset = load_dataset(\"yelp_review_full\")\n",
    "# dataset = load_dataset(\"amazon_reviews_multi\", \"en\", \"train\")\n",
    "# dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0dfd2be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset amazon_reviews_multi/en to /Users/apmcm/.cache/huggingface/datasets/amazon_reviews_multi/en-data_dir=train/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading data files: 100%|██████████████████| 1/1 [00:00<00:00, 910.82it/s]\u001b[A\n",
      "\n",
      "Extracting data files: 100%|███████████████████| 1/1 [00:00<00:00, 242.03it/s]\u001b[A\n",
      "\n",
      "Downloading data files: 100%|█████████████████| 1/1 [00:00<00:00, 1757.88it/s]\u001b[A\n",
      "\n",
      "Extracting data files: 100%|███████████████████| 1/1 [00:00<00:00, 291.80it/s]\u001b[A\n",
      "\n",
      "Downloading data files: 100%|█████████████████| 1/1 [00:00<00:00, 1173.56it/s]\u001b[A\n",
      "\n",
      "Extracting data files: 100%|███████████████████| 1/1 [00:00<00:00, 318.45it/s]\u001b[A\n",
      "\n",
      "Generating train split:   0%|               | 0/200000 [00:00<?, ? examples/s]\u001b[A\n",
      "Generating train split:   2%| | 3144/200000 [00:00<00:06, 31335.66 examples/s]\u001b[A\n",
      "Generating train split:   4%| | 7025/200000 [00:00<00:05, 35721.88 examples/s]\u001b[A\n",
      "Generating train split:   6%| | 11000/200000 [00:00<00:05, 37217.07 examples/s\u001b[A\n",
      "Generating train split:   7%| | 14942/200000 [00:00<00:04, 38076.01 examples/s\u001b[A\n",
      "Generating train split:   9%| | 18904/200000 [00:00<00:04, 38629.43 examples/s\u001b[A\n",
      "Generating train split:  11%| | 22816/200000 [00:00<00:04, 38793.79 examples/s\u001b[A\n",
      "Generating train split:  13%|▏| 26762/200000 [00:00<00:04, 39008.39 examples/s\u001b[A\n",
      "Generating train split:  16%|▏| 32698/200000 [00:00<00:04, 39240.54 examples/s\u001b[A\n",
      "Generating train split:  19%|▏| 38566/200000 [00:01<00:04, 39191.69 examples/s\u001b[A\n",
      "Generating train split:  22%|▏| 44443/200000 [00:01<00:03, 39183.56 examples/s\u001b[A\n",
      "Generating train split:  24%|▏| 48378/200000 [00:01<00:03, 39223.26 examples/s\u001b[A\n",
      "Generating train split:  26%|▎| 52319/200000 [00:01<00:03, 39270.03 examples/s\u001b[A\n",
      "Generating train split:  29%|▎| 58223/200000 [00:01<00:03, 39301.88 examples/s\u001b[A\n",
      "Generating train split:  31%|▎| 62155/200000 [00:01<00:03, 39304.57 examples/s\u001b[A\n",
      "Generating train split:  34%|▎| 68058/200000 [00:01<00:03, 39319.58 examples/s\u001b[A\n",
      "Generating train split:  36%|▎| 72016/200000 [00:01<00:03, 39383.14 examples/s\u001b[A\n",
      "Generating train split:  38%|▍| 76000/200000 [00:01<00:03, 39320.54 examples/s\u001b[A\n",
      "Generating train split:  40%|▍| 80000/200000 [00:02<00:03, 39243.15 examples/s\u001b[A\n",
      "Generating train split:  42%|▍| 84000/200000 [00:02<00:02, 39200.96 examples/s\u001b[A\n",
      "Generating train split:  44%|▍| 88000/200000 [00:02<00:02, 39230.56 examples/s\u001b[A\n",
      "Generating train split:  46%|▍| 92000/200000 [00:02<00:02, 39241.15 examples/s\u001b[A\n",
      "Generating train split:  48%|▍| 96000/200000 [00:02<00:02, 39245.75 examples/s\u001b[A\n",
      "Generating train split:  50%|▌| 100000/200000 [00:02<00:02, 39171.95 examples/\u001b[A\n",
      "Generating train split:  52%|▌| 104000/200000 [00:02<00:02, 39085.19 examples/\u001b[A\n",
      "Generating train split:  54%|▌| 108000/200000 [00:02<00:02, 39082.76 examples/\u001b[A\n",
      "Generating train split:  56%|▌| 112000/200000 [00:02<00:02, 39015.60 examples/\u001b[A\n",
      "Generating train split:  58%|▌| 116000/200000 [00:02<00:02, 39049.08 examples/\u001b[A\n",
      "Generating train split:  60%|▌| 119964/200000 [00:03<00:02, 39218.00 examples/\u001b[A\n",
      "Generating train split:  63%|▋| 125863/200000 [00:03<00:01, 39256.17 examples/\u001b[A\n",
      "Generating train split:  66%|▋| 131723/200000 [00:03<00:01, 39185.21 examples/\u001b[A\n",
      "Generating train split:  68%|▋| 135656/200000 [00:03<00:01, 39218.98 examples/\u001b[A\n",
      "Generating train split:  71%|▋| 141517/200000 [00:03<00:01, 39164.37 examples/\u001b[A\n",
      "Generating train split:  74%|▋| 147402/200000 [00:03<00:01, 39186.02 examples/\u001b[A\n",
      "Downloading data files:  67%|████████████      | 4/6 [12:37<06:18, 189.40s/it]\u001b[A\n",
      "\n",
      "Generating train split:  79%|▊| 157589/200000 [00:04<00:01, 35781.95 examples/\u001b[A\n",
      "Generating train split:  82%|▊| 163240/200000 [00:04<00:01, 36367.68 examples/\u001b[A\n",
      "Generating train split:  84%|▊| 167108/200000 [00:04<00:00, 36893.95 examples/\u001b[A\n",
      "Generating train split:  86%|▊| 171000/200000 [00:04<00:00, 37297.93 examples/\u001b[A\n",
      "Generating train split:  88%|▉| 175000/200000 [00:04<00:00, 37730.62 examples/\u001b[A\n",
      "Generating train split:  90%|▉| 179000/200000 [00:04<00:00, 38121.69 examples/\u001b[A\n",
      "Generating train split:  92%|▉| 183000/200000 [00:04<00:00, 38432.79 examples/\u001b[A\n",
      "Generating train split:  94%|▉| 187000/200000 [00:04<00:00, 38629.20 examples/\u001b[A\n",
      "Generating train split:  96%|▉| 191000/200000 [00:04<00:00, 38773.44 examples/\u001b[A\n",
      "Generating train split:  98%|▉| 196791/200000 [00:05<00:00, 38705.27 examples/\u001b[A\n",
      "                                                                              \u001b[A\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset amazon_reviews_multi downloaded and prepared to /Users/apmcm/.cache/huggingface/datasets/amazon_reviews_multi/en-data_dir=train/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 3/3 [00:00<00:00, 838.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'review_id': 'en_0143676',\n",
       " 'product_id': 'product_en_0610451',\n",
       " 'reviewer_id': 'reviewer_en_0377453',\n",
       " 'stars': 1,\n",
       " 'review_body': 'Two nights in the water tide to our dock in the lake..... I’d say something liked this.',\n",
       " 'review_title': 'Let the picture tell you how go this is',\n",
       " 'language': 'en',\n",
       " 'product_category': 'sports'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"amazon_reviews_multi\", \"en\", \"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "524708a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0dce060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'en',\n",
      " 'product_category': 'sports',\n",
      " 'product_id': 'product_en_0610451',\n",
      " 'review_body': 'Two nights in the water tide to our dock in the lake..... I’d '\n",
      "                'say something liked this.',\n",
      " 'review_id': 'en_0143676',\n",
      " 'review_title': 'Let the picture tell you how go this is',\n",
      " 'reviewer_id': 'reviewer_en_0377453',\n",
      " 'stars': 1}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(dataset[\"train\"][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e2a73a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "\n",
    "# small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "# small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edb069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(10))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f31fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=8)\n",
    "eval_dataloader = DataLoader(small_eval_dataset, batch_size=8)\n",
    "\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5) # 5 stars\n",
    "\n",
    "\n",
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70d044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "model.eval()\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a4c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bbbc2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlewp-chapter09] *",
   "language": "python",
   "name": "conda-env-mlewp-chapter09-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
